<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pieter Gijsbers, Mitar Milutinovic, Prabhant Singh, Joaquin Vanschoren">
<meta name="dcterms.date" content="2020-03-23">
<meta name="description" content="Exploring new dataset format options for OpenML.org">

<title>Finding a standard dataset format for machine learning – OpenML Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">OpenML Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/openml/blog"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Finding a standard dataset format for machine learning</h1>
                  <div>
        <div class="description">
          Exploring new dataset format options for OpenML.org
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">OpenML</div>
                <div class="quarto-category">Data</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Pieter Gijsbers, Mitar Milutinovic, Prabhant Singh, Joaquin Vanschoren </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 23, 2020</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Machine learning data is commonly shared in whatever form it comes in (e.g.&nbsp;images, logs, tables) without being able to make strict assumptions on what it contains or how it is formatted. This makes machine learning hard because you need to spend a lot of time figuring out how to parse and deal with it. Some datasets are accompanied with loading scripts, which are language-specific and may break, and some come with their own server to query the dataset. These do help, but are often not available, and still require us to handle every dataset individually.</p>
<p>With OpenML, we aim to take a stress-free, 'zen'-like approach to working with machine learning datasets. To make training data easy to use, OpenML serves thousands of datasets in the same format, with the same rich meta-data, so that you can directly load it (e.g.&nbsp;in numpy,pandas,…) and start building models without manual intervention. For instance, you can benchmark algorithms across hundreds of datasets in a simple loop.</p>
<p>For historical reasons, we have done this by internally storing all data in the <a href="https://www.cs.waikato.ac.nz/ml/weka/arff.html">ARFF</a> data format, a CSV-like text-based format that includes meta-data such as the correct feature data types. However, this format is loosely defined, causing different parsers to behave differently, and the current parsers are memory-inefficient which inhibits the use of large datasets. A more popular format these days is <a href="https://parquet.apache.org/">Parquet</a>, a binary single-table format. However, many current machine learning tasks require multi-table data. For instance, image segmentation or object detection tasks have both images and varying amounts of annotations per image.</p>
<p>In short, we are looking the best format to <em>internally</em> store machine learning datasets in the foreseeable future, to extend OpenML towards all kinds of modern machine learning datasets and serve them in a uniform way. This blog post presents out process and insights. We would love to hear your thoughts and experiences before we make any decision on how to move forward.</p>
<p><strong>Scope</strong></p>
<p>We first define the general scope of the usage of the format:</p>
<ul>
<li>It should be <strong>useful for data storage and transmission</strong>. We can always convert data during upload or download in OpenML's client APIs. For instance, people may upload a Python pandas dataframe to OpenML, and later get the same dataframe back, without realizing or caring how the data was stored in the meantime. If people want to store the data locally, they can download it in the format they like (e.g.&nbsp;a memory-mapped format like Arrow/Feather for fast reading or TFRecords for people using TensorFlow). Additional code can facilitate such conversions.</li>
<li>There should be a <strong>standard way to represent specific types of data</strong>, i.e.&nbsp;a fixed schema that can be verified. For instance, all tabular data should be stored in a uniform way. Without it, we would need dataset-specific code for loading, which requires maintenance, and it will be harder to check quality and extract meta-data.</li>
<li>The format should <strong>allow storing most (processed) machine learning datasets,</strong> including images, video, audio, text, graphs, and multi-tabular data such as object recognition tasks and relational data. Data such as images can be converted to numeric formats (e.g.&nbsp;pixel values) for storage in this format (and usage in machine learning).</li>
</ul>
<p><strong>Impact on OpenML (simplicity, maintenance)</strong></p>
<p>Since OpenML is a community project, we want to keep it as easy as possible to use and maintain:</p>
<ul>
<li>We aim to host datasets in an <em>S3</em> object store (min.io).</li>
<li>We prefer a <strong>single internal data format</strong> to reduce maintenance both server-side and client-side.</li>
<li>We need <strong>machine-readable schemas</strong> (in a specific language) that describe how a certain type of data is formatted. Examples would be a schema for tabular data, a schema for annotated image data, etc. Every dataset should specify the schema it satisfies, and we should be able to <strong>validate</strong> this. We aim to gradually roll out support form different types of data, starting with tabular, and including others only after schemas are defined.</li>
<li>We need to support batch data now, but ideally the format should allow data appending (streaming) in the future.</li>
</ul>
<p>When no agreed upon schema exists, we could offer a forum for the community to discuss and agree on a standard schema, in collaboration with other initiatives (e.g.&nbsp;<a href="https://frictionlessdata.io/">frictionlessdata</a>). For instance, new schemas could be created in a github repo to allow people to do create pull requests. They could be effectively used once they are merged.</p>
<p><strong>Requirements</strong></p>
<p>To draw up a shortlist of data formats, we used the following (soft) requirements:</p>
<ul>
<li>The format should be stable and <strong>fully maintained</strong> by an active community.</li>
<li><strong>Parsers in various programming languages</strong>, including well-maintained and stable libraries.</li>
<li><strong>Streaming read/writes</strong>, for easy conversion and memory efficiency.</li>
<li><strong>Version control</strong>, some way to <strong>see differences</strong> between versions.</li>
<li>Ideally, there is a way to <strong>detect bitflip errors</strong> during storage or transmission.</li>
<li>Ideally, <strong>fast read/writes</strong> and <strong>efficient storage</strong>.</li>
<li>Ideally, there should be support for storing <strong>sparse data</strong>.</li>
<li>Support for storing binary blobs and vectors of different lengths.</li>
<li>If possible, support for multiple ‘resources’ (e.g.&nbsp;collections of files or multiple relational tables).</li>
<li>Potentially, store some meta-data inside the file.</li>
</ul>
<p><strong>Shortlist</strong></p>
<p>We decided to investigate the following formats in more detail:</p>
<p><a href="https://arrow.apache.org/"><strong>Arrow</strong></a> <strong>/</strong> <a href="https://github.com/wesm/feather"><strong>Feather</strong></a></p>
<p>Benefits:</p>
<ul>
<li>Great for locally caching files after download</li>
<li>Memory-mapped, so very fast reads</li>
</ul>
<p>Drawbacks:</p>
<ul>
<li>Not stable enough yet and not ideal for long-term storage. The authors also discourage it for long-term storage.</li>
<li>Limited to one data structure per file, but that data structure can be complex (e.g.&nbsp;dict).</li>
</ul>
<p><a href="https://parquet.apache.org/"><strong>Parquet</strong></a></p>
<p>Benefits:</p>
<ul>
<li>Used in industry a lot, active developer community. Good community of practice.</li>
<li>Well-supported and maintained.</li>
<li>Has parsers in different languages, but not all Parquet features are supported in every library (see below).</li>
<li>Built-in compression (columnar storage), very efficient long-term data storage</li>
<li>Simple structure</li>
<li>Sparse data</li>
</ul>
<p>Drawbacks:</p>
<ul>
<li>The Python libraries (<a href="https://arrow.apache.org/docs/python/parquet.html">Arrow</a>, <a href="https://fastparquet.readthedocs.io/">fastparquet</a>) <strong>do not support partial read/writes</strong>. The Java/Go implementations do. Splitting up parquet files into many small files can be cumbersome.</li>
<li><strong>No version control, no meta-data storage, no schema enforcement.</strong> There are layers on top (e.g.&nbsp;delta lake) that do support this. Simple file versioning can also be done with S3.</li>
<li>The different parsers (e.g.&nbsp;<a href="https://arrow.apache.org/docs/python/parquet.html">Parquet support inside Arrow</a>, <a href="https://fastparquet.readthedocs.io/">fastparquet</a>) implement different parts of the Parquet format and different set of compression algorithms. Hence, parquet files <strong>may not be compatible between parsers</strong> (see <a href="https://fastparquet.readthedocs.io/en/latest/#caveats-known-issues">here</a> and <a href="https://kb.databricks.com/data/wrong-schema-in-files.html">here</a>.</li>
<li>Support <strong>limited to single-table storage</strong>. For instance, there doesn’t seem to be an apparent way to store an object detection dataset (with images and annotations) as a single parquet file.</li>
</ul>
<p><a href="https://www.sqlite.org/index.html"><strong>SQLite</strong></a></p>
<p>Benefits:</p>
<ul>
<li>Easy to use and comparably fast to HDF5 in our tests.</li>
<li>Very good support in all languages. It is <a href="https://docs.python.org/3.7/library/sqlite3.html">built-in</a> in Python.</li>
<li>Very flexible access to parts of the data. SQL queries can be used to select any subset of the data.</li>
</ul>
<p>Drawback:</p>
<ul>
<li>It supports <strong>only 2000 columns</strong>, and we have quite a few datasets with more than 2000 features. Hence, storing large tabular data will require mapping data differently, which would add a lot of additional complexity.</li>
<li>Writing SQL queries <strong>requires knowledge of the internal data structure</strong> (tables, keys,…).</li>
</ul>
<p><a href="https://www.hdfgroup.org/solutions/hdf5/"><strong>HDF5</strong></a></p>
<p>Benefits:</p>
<ul>
<li>Very good support in all languages. Has well-tested parsers, all using the same C implementation.</li>
<li>Widely accepted format in the deep learning community to store data and models.</li>
<li>Widely accepted format in many scientific domains (e.g.&nbsp;astronomy, bioinformatics,…)</li>
<li>Provides built-in compression. Constructing and loading datasets was reasonably fast.</li>
<li>Very flexible. Should allow to store any machine learning dataset as a single file.</li>
<li>Allows easy inclusion of meta-data inside the file, creating a self-contained file.</li>
<li>Self-descriptive: the structure of the data can be easily read programmatically. For instance, ‘dump -H -A 0 mydata.hdf5’ will give you a lot of detail on the structure of the dataset.</li>
</ul>
<p>Drawbacks:</p>
<ul>
<li>Complexity. We <strong>cannot make any a priori assumptions about how the data is structured</strong>. We need to define schema and implement code that automatically validates that a dataset follows a specific schema (e.g.&nbsp;using h5dump to see whether it holds a single dataframe that we could load into pandas). We are unaware of any initiatives to define such schema.</li>
<li>The format has a <strong>very long and detailed specification</strong>. While parsers exist we don’t really know whether they are fully compatible with each other.</li>
<li>Can become corrupt if not carefully used.</li>
</ul>
<p><strong>CSV</strong></p>
<p>Benefits:</p>
<ul>
<li>Very good support in all languages.</li>
<li>Easy to use, requires very little additional tooling</li>
<li>Text-based, so easy versioning with git LFS. Changes in different versions can be observed with a simple git diff.</li>
<li>The current standard used in <a href="https://frictionlessdata.io/">frictionlessdata</a>.</li>
<li>There exist schema to express certain types of data in CSV (see <a href="https://frictionlessdata.io/">frictionlessdata</a>).</li>
</ul>
<p>Drawbacks:</p>
<ul>
<li><strong>Not very efficient</strong> for storing floating point numbers</li>
<li><strong>Not ideal for very large datasets</strong> (when data does not fit in memory/disk)</li>
<li><strong>Many different dialects exist</strong>. We need to decide on a standardized dialect and enforce that only that dialect is used on OpenML (<a href="https://frictionlessdata.io/specs/csv-dialect/">https://frictionlessdata.io/specs/csv-dialect/</a>). The dialect specified in <a href="https://tools.ietf.org/html/rfc4180">RFC4180</a>, which uses the comma as delimiter and the quotation mark as quote character, is often recommended.</li>
</ul>
<p><strong>Overview</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>Parquet</th>
<th>HDF5</th>
<th>SQLite</th>
<th>CSV</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Consistency across <br>different platforms</td>
<td>?</td>
<td>✅</td>
<td>✅</td>
<td>✅ (dialect)</td>
</tr>
<tr class="even">
<td>Support and documentation</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="odd">
<td>Read/write speed</td>
<td>✅</td>
<td>so-so</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr class="even">
<td>Incremental <br>reads/writes</td>
<td>Yes, but not <br>supported by current<br> Python libs</td>
<td>✅</td>
<td>✅</td>
<td>Yes (but not <br>random access)</td>
</tr>
<tr class="odd">
<td>Supports very large and high-dimensional datasets</td>
<td>✅</td>
<td>✅</td>
<td>❌ (limited nr. columns<br> per table)</td>
<td>✅ Storing tensors<br> requires flattening.</td>
</tr>
<tr class="even">
<td>Simplicity</td>
<td>✅</td>
<td>❌ (basically full <br>file system)</td>
<td>✅ (it’s a database)</td>
<td>✅</td>
</tr>
<tr class="odd">
<td>Metadata support</td>
<td>Only minimal</td>
<td>✅</td>
<td>✅</td>
<td>❌ (requires separate <br> metadata file)</td>
</tr>
<tr class="even">
<td>Maintenance</td>
<td>Apache project, open<br> and quite <a href="https://www.slideshare.net/Hadoop_Summit/the-columnar-roadmap-apache-parquet-and-apache-arrow-102997214">active</a></td>
<td>Closed group,<br> but <a href="https://www.slideshare.net/HDFEOS/hdf5-roadmap-20192020">active</a> community on <br>Jira and conferences</td>
<td>Run by a <a href="https://www.sqlite.org/prosupport.html">company</a>.<br> Uses an email list.</td>
<td>✅</td>
</tr>
<tr class="odd">
<td>Available examples of<br> usage in ML</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr class="even">
<td>Flexibility</td>
<td>Only tabular</td>
<td>Very flexible, <br>maybe too flexible</td>
<td>Relational multi-table</td>
<td>Only tabular</td>
</tr>
<tr class="odd">
<td>Versioning/Diff</td>
<td>Only via S3 or delta lake</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr class="even">
<td>Different length vectors</td>
<td>As blob</td>
<td>✅</td>
<td>❌ ?</td>
<td>✅</td>
</tr>
</tbody>
</table>
<p><strong>Performance benchmarks</strong></p>
<p>There exist some prior benchmarks (<a href="https://tech.blueyonder.com/efficient-dataframe-storage-with-apache-parquet/">here</a> and <a href="https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d">here</a>) on storing dataframes. These only consider single-table datasets. For reading/writing, CSV is clearly slower and Parquet is clearly faster. For storage, Parquet is most efficient but zipped CSV as well. HDF requires a lot more disk space. We also ran our own <a href="https://gitlab.com/mitar/benchmark-dataset-formats">benchmark</a> to compare the writing performance of those data formats for very large and complex machine learning datasets, but could not find a way to store these in one file in Parquet.</p>
<p><strong>Version control</strong></p>
<p>Version control for large datasets is tricky. For text-based formats (CSV), we could use <a href="https://git-lfs.github.com/">git LFS</a> store the datasets and have automated versioning of datasets. We found it quite easy to export all current OpenML dataset to GitLab: <a href="https://gitlab.com/data/d/openml">https://gitlab.com/data/d/openml</a>.</p>
<p>The binary formats do not allow us to track changes in the data, only to recover the exact versions of the datasets you want (and their metadata). Potentially, extra tools could still be used to export the data to dataframes or text and then compare them. Delta Lake has version history support, but seemingly only for Spark operations done on the datasets.</p>
<p><strong>We need your help!</strong> If we have missed any format we should investigate, or misunderstood those we have investigated, or missed some best practice, please tell us. You are welcome to comment below, or send us an email at openmlhq@googlegroups.com</p>
<p><strong>Contributors to this blog post:</strong> Mitar Milutinovic, Prabhant Singh, Joaquin Vanschoren, Pieter Gijsbers, Andreas Mueller, Matthias Feurer, Jan van Rijn, Marcus Weimer, Marcel Wever, Gertjan van den Burg, Nick Poorman</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>